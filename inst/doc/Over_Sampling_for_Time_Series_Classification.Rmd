---
title: "Over Sampling for Time Series Classification"
author: "Matthew F. Dixon,  Diego Klabjan and Lan Wei"
date: "`r Sys.Date()`"
output: pdf_document
#highlight: tango
number_sections: yes
toc: yes
fig_caption: yes
bibliography: "referenceOSTSC.bib"
biblio-style: "ieeetr"
vignette: >
  %\VignetteIndexEntry{Over_Sampling_for_Time_Series_Classification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
 require(knitcitations)
 cleanbib()
 options("citation_format" = "pandoc")
```

## Abstract
The `OSTSC` package is a powerful oversampling approach for classifying univariant, but multinomial time series data. This vignette provides a brief overview of the over-sampling methodology implemented by the package. A tutorial of the OSTSC package is provided. We begin by providing three test cases for the user to quickly validate the functionality in the package.  To demonstrate the performance impact of OSTSC, we provide two medium size imbalanced time series datasets. Each example applies a TensorFlow implementation of a Long Short-Term Memory (LSTM) classifier - a type of a Recurrent Neural Network (RNN) classifier - to imbalanced time series.  The classifier performance is compared with and without oversampling. Finally, larger versions of these two datasets are evaluated to demonstrate the scalability of the package. The examples demonstrate that the OSTSC package improves the performance of RNN classifiers applied to highly imbalanced time series data. In particular, OSTSC is observed to increase the AUC of LSTM from 0.51 to 0.786 on a high frequency trading dataset consisting of 30,000 time series observations.

## Introduction

A significant number of learning problems involve the accurate classification of rare events or outliers from time series data. For example, the detection of a flash crash, rogue trading, or heart arrhythmia from an electrocardiogram. Due to the rarity of these events, machine learning classifiers for detecting these events may be biased towards avoiding false positives. This is because any potential for false positives is greatly exaggerated by the number of negative samples in the data set. 

Class imbalance problems are most easily addressed by treating the observations as conditionally independent. Then standard statistical techniques, such as oversampling the minority class or undersampling the majority class, or both, are applicable. @More2016 compared a batch of resampling techniques' classification performances on imbalanced datasets. Besides the conventional resampling approaches, More showed how ensemble methods retain as much original information from the majority class as possible when performing undersampling. Ensemble methods perform well and have gained popularity in the data mining literature. @Dubey2014 studied an ensemble system of feature selection and data sampling from an imbalanced Alzheimer's Disease Neuroimaging Initiative dataset. 

However the imbalanced time series classification problem is more complex when the time dimension needs to be accounted for. Not only is the assumption that the observations are conditionally independent too strong, but also the predictors may be cross-correlated too. The sample correlation structure may weaken or be entirely lost under application of the conventional resampling approaches described above. 

There are two existing research directions for imbalanced time series classification. One is to preserve the covariance structure during oversampling proposed by @Cao2011. Another is to conduct undersampling with various learning algorithms, proposed by @Liang2012. Both approaches are limited to binary classification and do not consider the more general problem of multi-loss classification.

A key assertation by @Cao2014 is that a time series sampling scheme should preserve the covariance structure. When the observations are conditionally dependent, this approach has been shown to outperform other sampling approaches such as undersampling the majority class, oversampling the minority class, and SMOTE. Our R package `Over Sampling for Time Series Classification` (OSTSC) is built on this idea. OSTSC first implements Enhanced Structure Preserving Oversampling (EPSO) of the minority class. It then uses a nearest neighbor method from the SMOTE family to generate synthetic positives. Specifically, it uses an Adaptive Synthetic Sampling Approach for Imbalanced Learning (ADASYN). Note that other packages such as @smotefamily2017 already implement SMOTE sampling techniques, including ADASYN. However an implementation of ADASYN has been provided in OSTSC for compatibility with the format required for use with EPSO and TensorFlow.

For examining the performance of oversampling for times series classification, RNNs are preferred (@Graves2013). Recently @Dixon2017 applied RNNs to imbalanced times series data used in high frequency trading. The RNN classifier predicts a price-flip in the limit order book based on a sequence of limit order book depths and market orders. The approach uses standard under-sampling of the majority class to improve the classifier performance. OSTSC provides a uni-variate sample of this data and demonstrates the application of EPSO and ADASYN to improve the performance of the RNN. The RNN is implemented in 'TensorFlow' (@Abadi2016) and made available in R by using a wrapper for 'Keras' (@keras), a high-level API for 'TensorFlow'. 

The current version of the package currently only supports univariant classification of time series. The extension to multi-features requires tensor computations which are not implemented here.

### Overview
This vignette provides a brief description of the sampling methodologies implemented. 
We introduce the OSTSC package and illustrate its application using various examples. For validation purposes only, we first apply OSTSC to three small built-in toy datasets. These datasets are not sufficiently large to demonstrate the methodology. However, they can be used to quickly verify that the OSTSC function generates a balanced dataset. 

For demonstrating the effect of OSTSC on LSTM performance, we provide two medium size datasets that can be computed with moderate computation. Finally, to demonstrate scalability, we evaluate OSTSC on two larger datasets. The reader is advised that the total amount of computation in this case is significant. We would therefore expect a user to test the OSTSC functionality on the small or medium size datasets, but reserve running the larger dataset examples on a higher performance machine. The medium and large datasets are not built-in to keep the package size within 5MB.

## Background

ESPO is used to generate a large percentage of the synthetic minority samples from univariate labeled time series under the modeling assumption that the predictors are Gaussian. EPSO estimates the covariance structure of the minority-class samples and applies a spectral filter to reduce noise. ADASYN is a nearest neighbor interpolation approach which is subsequently applied to the EPSO samples (@Cao2013).

More formally, given the time series of positive labeled predictors $P = \left \{ x_{11}, x_{12}, ..., x_{1|P|}\right \}$ and the negative time series $N = \left \{ x_{01}, x_{02}, ..., x_{0|N|}\right \}$, where $|N| \gg |P|$, $x_{ij} \in \mathbb{R}^{n \times 1}$, the new samples are generated by the following steps:

1. Removal of the Common Null Space

Let $q_{ij} = L_{s}^{T}x_{ij}$ represent $x_{ij}$ in a lower-dimensional signal space, where $L_{s}$ consists of eigenvectors in the signal space.

2. ESPO

Let $\hat{D}$ denote the diagonal matrix of regularized eigenvalues $\left \{ \hat{d_{1}}, ..., \hat{d_{n}}\right \}$ organized in descending order. Let $V$ be the orthogonal  eigenvector matrix from the positive-class covariance matrix:

$$W_p=\frac{1}{|P|}\sum_{j=1}^{|P|}(q_{1j}-\bar{q}_1)(q_{1j}-\bar{q}_1)^T.$$
Let $b$ denote the synthetic positive sample to be generated.
The transformed version of $b$ follows a zero-mean mixed Gaussian distribution which we denote as $z = \hat{F}(b-\bar{q_{1}})$, where $\hat{F} = V\hat{D}^{-1/2}$ and $\bar{q_{1}}$ is the corresponding positive-class mean vector. Substituting the definition of $\hat{F}$ in to the expression for $z$ and rearranging gives
\begin{eqnarray*}
z &=& \hat{F}(b-\bar{q_{1}})\\
z &=& V\hat{D}^{-1/2}(b-\bar{q_{1}})\\
\hat{D}^{1/2}V^Tz&=&b-\bar{q_{1}}\\
b&=&\hat{D}^{1/2}V^Tz + \bar{q_{1}}
\end{eqnarray*}
which is used to generate b once $z$ is drawn from the mixed Gaussian distribution. The oversampling is repeated until all $(|N|-|P|)r$ required synthetic samples are generated, where $r\in[0,1]$ is the integration percentage of synthetic samples contributed by ESPO, which is chosen empirically. The remaining $(1-r)$ percentage of the samples are generated by the interpolation procedure described next.

3. ADASYN

Given the transformed positive data $P_{t} = \left \{ q_{1i}\right \}$ and negative data $N_{t} = \left \{ q_{0j}\right \}$, each sample $q_{1i}$ is replicated $\Gamma_{i} = \left | S_{i:k-NN}\bigcap N_{t} \right | /Z$ times, where $S_{i:k-NN}$ is this sample's kNN in the entire dataset, $Z$ is a normalization factor so that $\sum_{i=1}^{|P_{t}|}\Gamma _{i} = 1$. 

See @Cao2013 for further technical details of this approach.

## Functionality

The package imports 'parallel' (@parallel), 'doParallel' (@doParallel), 'doSNOW' (@doSNOW) and 'foreach' (@foreach) for multi-threaded execution on shared memory architectures. Parallel execution is strongly suggested for datasets consisting of at least 30,000 observations. OSTSC also imports 'mvrnorm' from 'MASS' (@MASS) to generate random vectors from the multivariate normal distribution, and 'rdist' from 'fields' (@fields) in order to calculate the Euclidean distance between vectors and matrices.

This vignette displays some simple examples below. For calling the RNN and examining the classifier's performance, 'keras' (@keras), 'dummies' (@dummies) and 'pROC' (@pROC) are required.

## Examples

### Data loading & oversampling

The OSTSC package provides three small built-in datasets for verification that OSTSC has correctly installed and generates balanced time series. The first two examples use OSTSC to balance binary data while the third balances multinomial data.

#### The synthetically generated control dataset

The dataset `Dataset_Synthetic_Control` is a time series of sensor measurements of human body motion generated by @Alcock1999. We introduce the following labeling: Class 1 represents the 'Normal' state, while Class 0 represents one of 'Cyclic', 'Increasing trend', 'Decreasing trend', 'Upward shift' or 'Downward shift' (@Pham1998). Users load the dataset by calling `data()`.

```{r, echo=FALSE, message=FALSE}
require(OSTSC)
require(keras)
require(dummies)
require(pROC)
rfv <- local(get(load(url('https://github.com/lweicdsor/GSoC2017/raw/master/ResultForVignettes.rdata'))))
rfvn <- local(get(load(url('https://github.com/lweicdsor/GSoC2017/raw/master/ResultForVignettesNew.rdata'))))
```
```{r}
data(Dataset_Synthetic_Control)

train.label <- Dataset_Synthetic_Control$train.y
train.sample <- Dataset_Synthetic_Control$train.x
test.label <- Dataset_Synthetic_Control$test.y
test.sample <- Dataset_Synthetic_Control$test.x
```

Each row of the dataset is a sequence of observations. The sequence is of length 60 and there are 300 observations.

```{r, }
dim(train.sample)
```

The imbalance ratio of the training data is 1:5.

```{r, }
table(train.label)
```

We now provide a simple example demonstrating oversampling of the minority data to match the number of observations of the majority class. The output 'MyData' stores the samples (a.k.a. features) and labels. There are ten parameters in the OSTSC function, the details of which can be found in the help documentation. Calling the OSTSC function requires the user to provide at least the labels and sample data - the other parameters have default values. It is important to note that the labels are separated from the samples. 

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```

The positive and negative observations are now balanced. Let us check the (im)balance of the new dataset.

```{r}
table(over.label)
```

The minority class data is oversampled to produce a balanced feature set. The minority-majority formation uses a one-vs-rest strategy. For this binary dataset, the Class 1 data has been oversampled to yield the same number of observations as Class 0.

```{r, }
dim(over.sample)
```

#### The automatic diatoms identification dataset

The dataset `Dataset_Adiac` is generated from a pilot study identifying diatoms (unicellular algae) from images by @Jalba2004 originally has 37 classes. For the purpose of demonstrating OSTSC we selected only one class as the positive class (Class 1) and all others are set as the negative class (Class 0) to form a highly imbalanced dataset. Users load the dataset into R by calling `data()`.

```{r}
data(Dataset_Adiac)

train.label <- Dataset_Adiac$train.y
train.sample <- Dataset_Adiac$train.x
test.label <- Dataset_Adiac$test.y
test.sample <- Dataset_Adiac$test.x
```

The training dataset consists of 390 observations of a 176 length sequence.

```{r, }
dim(train.sample)
```

The imbalance ratio of the training data is 1:29.

```{r, }
table(train.label)
```

The OSTSC function generates a balanced dataset: 

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```

table() provides a summary of the balanced dataset.

```{r}
table(over.label)
```

#### The high frequency trading dataset 

The OSTSC function provides support for multinomial classification. The user specifies which classes should be oversampled. Typically, oversampling is first applied to the minority class - the class with the least number of observations.
The dataset `Dataset_HFT300` is extracted from a real high frequency trading datafeed (@Dixon2017). It contains a feature representing instantaneous liquidity imbalance using the best bid to ask ratio. The data is labeled so that $Y=1$ for a next event mid-price up-tick, $Y=-1$ for a down-tick, and $Y=0$ for no mid-price movement.  
Users load the dataset into the R environment by calling `data()`.

```{r}
data(Dataset_HFT300)

train.label <- Dataset_HFT300$y
train.sample <- Dataset_HFT300$x
```

The sequence length is set to 10 and 300 sequence observations are randomly drawn for this example dataset.

```{r, }
dim(train.sample)
```

The imbalance ratio of the three class dataset is 1:48:1.

```{r, }
table(train.label)
```

This example demonstrates the case when there are two minority classes and both are over-sampled. The oversampling is processed using a one-vs-rest strategy, which means that each minority class is oversampled to the same count as the sum of the count of all other classes. This results in a slight imbalance in the total number of labels. 

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```

We observe the ratio of the classes after oversampling.

```{r}
table(over.label)
```

The above examples illustrate how OSTSC oversamples small datasets. In the next section, we demonstrate and evaluate the oversampled data on two medium size datasets.

### Applying OSTSC to medium size datasets

#### The Electrical Devices dataset

The dataset `Dataset_ElectricalDevices` is a sample collected from the 'Powering the Nation' study (@Lines2011). This study seeks to reduce the UK's carbon footprint by  collecting behavioural data on how consumers use electricity within the home. Each class represent a signal from a different electrical device. Classes 5 and 6 in the original dataset are set as the negative and positive respectively. The dataset is split into training and testing features and labels.

```{r}
ElectricalDevices <- Dataset_ElectricalDevices()

train.label <- ElectricalDevices$train.y
train.sample <- ElectricalDevices$train.x
test.label <- ElectricalDevices$test.y
test.sample <- ElectricalDevices$test.x
```

Each row in the data represents a sequence of length 96. 

```{r, }
dim(train.sample)
```

The imbalance ratio of the training data is 1:4.7.

```{r, }
table(train.label)
```

After oversampling with OSTSC, the positive and negative observations are balanced.

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```
```{r}
table(over.label)
```

A LSTM classifier is used as the basis for performance assessment of oversampling with OSTSC. We use 'keras' (@keras) to configure the architecture, hyper-parameters and learning schedule of the LSTM classifier for sequence classification. 

As a baseline for OSTSC, we assess the performance of LSTM trained on the unbalanced and balanced data. The procedure for applying Keras is next outlined:

1. One-hot encode the categorical label vectors as binary class matrices using the Keras 'to_categorical()' function. Then transform the feature matrices to tensors for LSTM.

```{r, eval = FALSE}
library(keras)
train.y <- to_categorical(train.label)
test.y <- to_categorical(test.label)
train.x <- array(train.sample, dim = c(dim(train.sample),1)) 
test.x <- array(test.sample, dim = c(dim(test.sample),1)) 
```
```{r, eval = FALSE}
over.y <- to_categorical(over.label)
over.x <- array(over.sample, dim = c(dim(over.sample),1)) 
```

2. Initialize a sequential model, add layers and then compile it. Measure the losses and F1 values after each epoch and display them in Figure 1 and Figure 2. 
```{r, eval = FALSE}
 K <- backend()
 metric_f1 <- function(y_true, y_pred) {
        true_positives <- K$sum(K$round(K$clip(y_true * y_pred, 0, 1)))
        possible_positives <- K$sum(K$round(K$clip(y_true, 0, 1)))
        recall <- true_positives / (possible_positives + K$epsilon())
        
        predicted_positives <- K$sum(K$round(K$clip(y_pred, 0, 1)))
        precision <- true_positives / (predicted_positives + K$epsilon())
        return(2*((precision*recall)/(precision+recall+ K$epsilon())))
 }
 LossHistory <- R6::R6Class("LossHistory",
                           inherit = KerasCallback,
                           
                           public = list(
                             
                             losses = NULL,
                             f1s    = NULL,
                             val_f1s= NULL,
                             
                             on_epoch_end = function(epoch, logs = list()) {
                               self$losses <- c(self$losses, logs[["loss"]])
                               self$f1s    <- c(self$f1s, logs[["f1_score"]])
                               self$val_f1s    <- c(self$val_f1s, logs[["val_f1_score"]])
                             }
                           ))
```

```{r, eval = FALSE}
model <- keras_model_sequential()
model %>%
  layer_lstm(10, input_shape = c(dim(train.x)[2], dim(train.x)[3])) %>%
  layer_dropout(rate = 0.2) %>% 
  layer_dense(dim(train.y)[2]) %>%
  layer_dropout(rate = 0.2) %>% 
  layer_activation("softmax")
history <- LossHistory$new()
model %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = "adam",
  metrics = c("accuracy",'f1_score' = metric_f1)
)
lstm.before <- model %>% fit( 
  x = train.x, 
  y = train.y, 
  validation_split = 0.2,
  callbacks = list(history),
  epochs = 20
)
history.loss <- history$losses
history.f1 <- history$val_f1s
```
```{r, eval = FALSE}
model.over <- keras_model_sequential()
model.over %>%
  layer_lstm(10, input_shape = c(dim(over.x)[2], dim(over.x)[3])) %>%
  layer_dropout(rate = 0.1) %>% 
  layer_dense(dim(over.y)[2]) %>%
  layer_dropout(rate = 0.1) %>% 
  layer_activation("softmax")
history.over <- LossHistory$new()
model.over %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = "adam", 
  metrics = c("accuracy",'f1_score' = metric_f1)
)
lstm.after <- model.over %>% fit( 
  x = over.x, 
  y = over.y, 
  validation_split = 0.2,
  callbacks = list(history.over),
  epochs = 20
)
history.loss.over <- history.over$losses
history.f1.over <- history.over$val_f1s
```
```{r, echo = FALSE, message=FALSE}
pred.label <- as.vector(unlist(rfv$EDp1)) 
history.loss <- rfvn$EDl1 
history.f1 <- rfvn$EDf1
```
```{r, echo = FALSE, message=FALSE}
pred.label.over <- as.vector(unlist(rfv$EDp2)) 
history.loss.over <- rfvn$EDl2 
history.f1.over <- rfvn$EDf2
```
```{r, fig.width = 6, fig.height = 5, fig.cap = "The losses of the LSTM classifier trained on the unbalanced and balanced Electrical Devices dataset. Both metrics are evaluated at the end of each epoch.", echo = FALSE}
plot(history.loss, type = "b", pch = 19, col = "blue", main = "Loss of the LSTM classifier on Electrical Devices dataset", yaxt = "n", xaxt = "n", xlab = "Epoches", ylab = "", ylim = c(0.0, 2.0), xlim = c(0, 20))
lines(history.loss.over, type = "b", pch = 19, col = "red")
axis(1, at = c(0,2,4,6,8,10,12,14,16,18,20),labels = c(0,2,4,6,8,10,12,14,16,18,20), las = 1)
axis(2, at = c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2), labels = c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2), las = 1)
mtext("Loss", side = 2, las = 1, line = 2)
legend("topleft", legend = c("Balanced dataset", "Unbalanced dataset"), col = c("red","blue"), bty = "n", lwd = 2, cex = 0.7)
```
```{r, fig.width = 6, fig.height = 5, fig.cap = "The F1 values of the LSTM classifier trained on the unbalanced and balanced Electrical Devices dataset. Both metrics are evaluated at the end of each epoch.", echo = FALSE}
plot(history.f1.over, type = "b", pch = 19, col = "red", main = "F1 of the LSTM classifier on Electrical Devices dataset", yaxt = "n", xaxt = "n", xlab = "Epoches", ylab = "", ylim = c(0.0, 1.0), xlim = c(0, 20))
lines(history.f1, type = "b", pch = 19, col = "blue")
axis(1, at = c(0,2,4,6,8,10,12,14,16,18,20),labels = c(0,2,4,6,8,10,12,14,16,18,20), las = 1)
axis(2, at = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), labels = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), las = 1)
mtext("F1", side = 2, las = 1, line = 3)
legend("topleft", legend = c("Balanced dataset", "Unbalanced dataset"), col = c("red","blue"), bty = "n", lwd = 2, cex = 0.7)
```

From the losses and F1 values history, we note that the model has not yet been adequately trained, but nevertheless serves as the basis for a quick comparison with OSTSC (with the same number of epoches). The user can of course increase the number of epoches but this will increase the computation time.

In addition to the training history, Figures 3 and 4 compare the confusion matrices of the two models without and with oversampling. Figure 5 compares the receiver operating characteristic (ROC) curves of the models. Before oversampling, the LSTM classifier performance is only marginally better than white noise. However, for the same number of epoches, oversampling improves the performance. 

```{r, eval = FALSE}
pred.label <- model %>% predict_classes(test.x)
pred.label.over <- model.over %>% predict_classes(test.x)
```
```{r}
cm.before <- table(test.label, pred.label)
cm.after <- table(test.label, pred.label.over)
```
```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the Electrical Devices dataset without oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 240, 370, col='#3F97D0')
rect(250, 430, 340, 370, col='#F7AD50')
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(195, 435, '5', cex=1.1)
text(295, 435, '6', cex=1.1)
text(125, 370, 'True', cex=1.2, srt=90, font=2)
text(245, 450, 'Predicted', cex=1.2, font=2)
text(140, 400, '5', cex=1.1, srt=90)
text(140, 335, '6', cex=1.1, srt=90)

res <- as.numeric(cm.before)
for (i in 1:4){
  res[i][is.na(res[i])] <- 0
}
sum1 <- res[1] + res[3]
sum2 <- res[2] + res[4] 
text(195, 400, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(195, 335, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(295, 400, round(res[3]/sum1, 4), cex=1.3, font=2, col='white')
text(295, 335, round(res[4]/sum2, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the Electrical Devices dataset with oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 240, 370, col='#3F97D0')
rect(250, 430, 340, 370, col='#F7AD50')
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(195, 435, '5', cex=1.1)
text(295, 435, '6', cex=1.1)
text(125, 370, 'True', cex=1.2, srt=90, font=2)
text(245, 450, 'Predicted', cex=1.2, font=2)
text(140, 400, '5', cex=1.1, srt=90)
text(140, 335, '6', cex=1.1, srt=90)

res <- as.numeric(cm.after)
for (i in 1:4){
  res[i][is.na(res[i])] <- 0
}
sum1 <- res[1] + res[3]
sum2 <- res[2] + res[4] 
text(195, 400, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(195, 335, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(295, 400, round(res[3]/sum1, 4), cex=1.3, font=2, col='white')
text(295, 335, round(res[4]/sum2, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 4, fig.height = 4, fig.cap = "ROC curves comparing the effect of oversampling on the performance of LSTM applied to the Electrical Devices dataset."}
library(pROC)
par(pty = "s")
plot.roc(as.vector(test.label), pred.label, legacy.axes = TRUE, col = "blue", print.auc = TRUE,  
         print.auc.cex= .8, xlab = 'False Positive Rate', ylab = 'True Positive Rate') 
plot.roc(as.vector(test.label), pred.label.over, legacy.axes = TRUE, col = "red", print.auc = TRUE,   
         print.auc.y = .4, print.auc.cex= .8, add = TRUE)
legend("bottomright", legend=c("Without oversampling", "With oversampling"), 
       col=c("blue", "red"), lwd=2, cex= .6)
```

#### The Electrocardiogram dataset 

The dataset `Dataset_ECG` was originally created by @Goldberger2015 and records heartbeats from patients with severe congestive heart failure. The dataset was pre-processed to extract heartbeat sequences and add labels by @Chen2015. The OSTSC package uses 5,000 randomly selected heartbeat sequences. 

```{r}
ECG <- Dataset_ECG()

train.label <- ECG$train.y
train.sample <- ECG$train.x
test.label <- ECG$test.y
test.sample <- ECG$test.x
```

Each row in the data represents a sequence of length 140. 

```{r}
dim(train.sample)
```

This experiment uses 4 classes of the dataset to ensure a high degree of imbalance: the imbalance ratio is 119:4:8:1.

```{r}
table(train.label)
```

Let us check that the data is balanced after oversampling. 

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```
```{r}
table(over.label)
```

We evaluate the effect of oversampling on the performance of LSTM following Steps 1-3 above. First the data is transformed:

```{r, eval = FALSE}
library(keras)
library(dummies)
train.y <- dummy(train.label)
test.y <- dummy(test.label)
train.x <- array(train.sample, dim = c(dim(train.sample),1)) 
test.x <- array(test.sample, dim = c(dim(test.sample),1)) 
```
```{r, eval = FALSE}
over.y <- dummy(over.label)
over.x <- array(over.sample, dim = c(dim(over.sample),1)) 
```

After configuring and training the model, the losses and F1 values are measured at the end of each epoch and shown in Figure 6 and Figure 7. 
```{r, eval = FALSE}
model <- keras_model_sequential()
model %>%
  layer_lstm(10, input_shape = c(dim(train.x)[2], dim(train.x)[3])) %>%
  layer_dropout(rate = 0.2) %>% 
  layer_dense(dim(train.y)[2]) %>%
  layer_dropout(rate = 0.2) %>% 
  layer_activation("softmax")
history <- LossHistory$new()
model %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = "adam",
  metrics = c("accuracy",'f1_score' = metric_f1)
)
lstm.before <- model %>% fit( 
  x = train.x, 
  y = train.y, 
  validation_split = 0.2,
  callbacks = list(history),
  epochs = 20
)
history.loss <- history$losses
history.f1 <- history$val_f1s
```
```{r, eval = FALSE}
model.over <- keras_model_sequential()
model.over %>%
  layer_lstm(10, input_shape = c(dim(over.x)[2], dim(over.x)[3])) %>%
  layer_dropout(rate = 0.1) %>% 
  layer_dense(dim(over.y)[2]) %>%
  layer_dropout(rate = 0.1) %>% 
  layer_activation("softmax")
history.over <- LossHistory$new()
model.over %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = "adam", 
  metrics = c("accuracy",'f1_score' = metric_f1)
)
lstm.after <- model.over %>% fit( 
  x = over.x, 
  y = over.y, 
  validation_split = 0.2,
  callbacks = list(history.over),
  epochs = 20
)
history.loss.over <- history.over$losses
history.f1.over <- history.over$val_f1s
```
```{r, echo = FALSE, message=FALSE}
pred.label <- as.vector(unlist(rfv$ECGp1)) 
history.loss <- rfvn$ECGl1 
history.f1 <- rfvn$ECGf1
```
```{r, echo = FALSE, message=FALSE}
pred.label.over <- as.vector(unlist(rfv$ECGp2)) 
history.loss.over <- rfvn$ECGl2 
history.f1.over <- rfvn$ECGf2
```
```{r, fig.width = 6, fig.height = 5, fig.cap = "The losses of the LSTM classifier trained on the unbalanced and balanced Electrocardiogram dataset. Both metrics are evaluated at the end of each epoch.", echo = FALSE}
plot(history.loss, type = "b", pch = 19, col = "blue", yaxt = "n", xaxt = "n", 
     xlab = "Epoches", ylab = "", ylim = c(0.0, 2.0), xlim = c(0, 20), 
     main = "Loss of the LSTM classifier on Electrocardiogram dataset")
lines(history.loss.over, type = "b", pch = 19, col = "red")
axis(1, at = c(0,2,4,6,8,10,12,14,16,18,20),labels = c(0,2,4,6,8,10,12,14,16,18,20), 
     las = 1)
axis(2, at = c(0.0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0), 
     labels = c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2), las = 1)
mtext("Loss", side = 2, las = 1, line = 2)
legend("topleft", legend = c("Balanced dataset", "Unbalanced dataset"), 
       col = c("red","blue"), bty = "n", lwd = 2, cex = 0.7)
```
```{r, fig.width = 6, fig.height = 5, fig.cap = "The F1 values of the LSTM classifier trained on the unbalanced and balanced Electrocardiogram dataset. Both metrics are evaluated at the end of each epoch.", echo = FALSE}
plot(history.f1.over, type = "b", pch = 19, col = "red", yaxt = "n", xaxt = "n", 
     xlab = "Epoches", ylab = "", ylim = c(0.0, 1.0), xlim = c(0, 20), 
     main = "F1 of the LSTM classifier on Electrocardiogram dataset")
lines(history.f1, type = "b", pch = 19, col = "blue")
axis(1, at = c(0,2,4,6,8,10,12,14,16,18,20),labels = c(0,2,4,6,8,10,12,14,16,18,20), 
     las = 1)
axis(2, at = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), 
     labels = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), las = 1)
mtext("F1", side = 2, las = 1, line = 3)
legend("topleft", legend=c("Balanced dataset", "Unbalanced dataset"), 
       col = c("red", "blue"), bty = "n", lwd = 2, cex = 0.7)
```


From the losses and F1 values, we note that the model has not yet been adequately trained after 20 epoches. Keep in mind that we are trying to demonstrate the utility of OSTSC with only a modest amount of computation. The user can of course choose to increase the number of epoches, but will this of course require more computation. The user should also see the larger datasets section below, where more epoches are used for training LSTM.

Keeping the number of epoches fixed, Figures 8, 9 and 10 respectively compare the confusion matrices and ROC curves of LSTM without and with oversampling. Before oversampling, the LSTM classifier performance is only marginally better than white noise. However, for the same number of epoches, oversampling improves the performance. 

```{r, eval = FALSE}
pred.label <- model %>% predict_classes(test.x)
pred.label.over <- model.over %>% predict_classes(test.x)
```
```{r}
cm.before <- table(test.label, pred.label)
cm.after <- table(test.label, pred.label.over)
```
```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the Electrocardiogram dataset without oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(290, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 195, 400, col='#3F97D0')
rect(200, 430, 245, 400, col='#F7AD50')
rect(250, 430, 295, 400, col='#F7AD50')
rect(300, 430, 345, 400, col='#F7AD50')

rect(150, 395, 195, 365, col='#F7AD50')
rect(200, 395, 245, 365, col='#3F97D0')
rect(250, 395, 295, 365, col='#F7AD50')
rect(300, 395, 345, 365, col='#F7AD50')

rect(150, 360, 195, 330, col='#F7AD50')
rect(200, 360, 245, 330, col='#F7AD50')
rect(250, 360, 295, 330, col='#3F97D0')
rect(300, 360, 345, 330, col='#F7AD50')

rect(150, 325, 195, 295, col='#F7AD50')
rect(200, 325, 245, 295, col='#F7AD50')
rect(250, 325, 295, 295, col='#F7AD50')
rect(300, 325, 345, 295, col='#3F97D0')

text(172, 435, '1', cex=1.1)
text(222, 435, '3', cex=1.1)
text(272, 435, '4', cex=1.1)
text(322, 435, '5', cex=1.1)
text(140, 415, '1', cex=1.1, srt=90)
text(140, 380, '3', cex=1.1, srt=90)
text(140, 345, '4', cex=1.1, srt=90)
text(140, 310, '5', cex=1.1, srt=90)
text(120, 370, 'True', cex=1.2, srt=90, font=2)
text(240, 450, 'Predicted', cex=1.2, font=2)
  
res <- as.numeric(cm.before)
for (i in 1:16){
  res[i][is.na(res[i])] <- 0
}
sum1 <- res[1] + res[5] + res[9] + res[13]
sum2 <- res[2] + res[6] + res[10] + res[14]
sum3 <- res[3] + res[7] + res[11] + res[15]
sum4 <- res[4] + res[8] + res[12] + res[16]
text(172, 415, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(172, 380, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(172, 345, round(res[3]/sum3, 4), cex=1.3, font=2, col='white')
text(172, 310, round(res[4]/sum4, 4), cex=1.3, font=2, col='white')
text(222, 415, round(res[5]/sum1, 4), cex=1.3, font=2, col='white')
text(222, 380, round(res[6]/sum2, 4), cex=1.3, font=2, col='white')
text(222, 345, round(res[7]/sum3, 4), cex=1.3, font=2, col='white')
text(222, 310, round(res[8]/sum4, 4), cex=1.3, font=2, col='white')
text(272, 415, round(res[9]/sum1, 4), cex=1.3, font=2, col='white')
text(272, 380, round(res[10]/sum2, 4), cex=1.3, font=2, col='white')
text(272, 345, round(res[11]/sum3, 4), cex=1.3, font=2, col='white')
text(272, 310, round(res[12]/sum4, 4), cex=1.3, font=2, col='white')
text(322, 415, round(res[13]/sum1, 4), cex=1.3, font=2, col='white')
text(322, 380, round(res[14]/sum2, 4), cex=1.3, font=2, col='white')
text(322, 345, round(res[15]/sum3, 4), cex=1.3, font=2, col='white')
text(322, 310, round(res[16]/sum4, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the Electrocardiogram dataset with oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(290, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 195, 400, col='#3F97D0')
rect(200, 430, 245, 400, col='#F7AD50')
rect(250, 430, 295, 400, col='#F7AD50')
rect(300, 430, 345, 400, col='#F7AD50')

rect(150, 395, 195, 365, col='#F7AD50')
rect(200, 395, 245, 365, col='#3F97D0')
rect(250, 395, 295, 365, col='#F7AD50')
rect(300, 395, 345, 365, col='#F7AD50')

rect(150, 360, 195, 330, col='#F7AD50')
rect(200, 360, 245, 330, col='#F7AD50')
rect(250, 360, 295, 330, col='#3F97D0')
rect(300, 360, 345, 330, col='#F7AD50')

rect(150, 325, 195, 295, col='#F7AD50')
rect(200, 325, 245, 295, col='#F7AD50')
rect(250, 325, 295, 295, col='#F7AD50')
rect(300, 325, 345, 295, col='#3F97D0')

text(172, 435, '1', cex=1.1)
text(222, 435, '3', cex=1.1)
text(272, 435, '4', cex=1.1)
text(322, 435, '5', cex=1.1)
text(140, 415, '1', cex=1.1, srt=90)
text(140, 380, '3', cex=1.1, srt=90)
text(140, 345, '4', cex=1.1, srt=90)
text(140, 310, '5', cex=1.1, srt=90)
text(120, 370, 'True', cex=1.2, srt=90, font=2)
text(240, 450, 'Predicted', cex=1.2, font=2)
  
res <- as.numeric(cm.after)
for (i in 1:16){
  res[i][is.na(res[i])] <- 0
}
sum1 <- res[1] + res[5] + res[9] + res[13]
sum2 <- res[2] + res[6] + res[10] + res[14]
sum3 <- res[3] + res[7] + res[11] + res[15]
sum4 <- res[4] + res[8] + res[12] + res[16]
text(172, 415, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(172, 380, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(172, 345, round(res[3]/sum3, 4), cex=1.3, font=2, col='white')
text(172, 310, round(res[4]/sum4, 4), cex=1.3, font=2, col='white')
text(222, 415, round(res[5]/sum1, 4), cex=1.3, font=2, col='white')
text(222, 380, round(res[6]/sum2, 4), cex=1.3, font=2, col='white')
text(222, 345, round(res[7]/sum3, 4), cex=1.3, font=2, col='white')
text(222, 310, round(res[8]/sum4, 4), cex=1.3, font=2, col='white')
text(272, 415, round(res[9]/sum1, 4), cex=1.3, font=2, col='white')
text(272, 380, round(res[10]/sum2, 4), cex=1.3, font=2, col='white')
text(272, 345, round(res[11]/sum3, 4), cex=1.3, font=2, col='white')
text(272, 310, round(res[12]/sum4, 4), cex=1.3, font=2, col='white')
text(322, 415, round(res[13]/sum1, 4), cex=1.3, font=2, col='white')
text(322, 380, round(res[14]/sum2, 4), cex=1.3, font=2, col='white')
text(322, 345, round(res[15]/sum3, 4), cex=1.3, font=2, col='white')
text(322, 310, round(res[16]/sum4, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 4, fig.height = 4, fig.cap = "ROC curves of LSTM applied to the Electrocardiogram dataset, with and without oversampling."}
library(pROC)
par(pty = "s")
plot.roc(as.vector(test.label), pred.label, legacy.axes = TRUE, col = "blue", print.auc = TRUE,  
         print.auc.cex= .8, xlab = 'False Positive Rate', ylab = 'True Positive Rate')
plot.roc(as.vector(test.label), pred.label.over, legacy.axes = TRUE, col = "red", print.auc = TRUE,   
         print.auc.y = .4, print.auc.cex= .8, add = TRUE)
legend("bottomright", legend=c("Without oversampling", "With oversampling"), 
       col=c("blue", "red"), lwd=2, cex= .6)
```

### Evaluating OSTSC on the large datasets

The evaluation of oversampling next uses larger datasets:  the MHEALTH and the HFT datasets. The purpose of this evaluation is to demonstrate how OSTSC performs at scale. We increase the data sizes by factor of up to 10x. The evaluation of each dataset takes approximately three hours on a 1.7 GHz four-core laptop with 8GM of RAM.

#### The MHEALTH dataset

The dataset `Dataset_MHEALTH` benchmarks techniques for human behavioral analysis applied to multimodal body sensing (@Banos2014).
In this experiment, only Subjects 1-5 and Feature 12 (the x coordinate of the magnetometer reading from the left-ankle sensor) are used. The dataset is labeled with a dichotonomous response (@Banos2015). Class 11 (Running) is set as the positive and the remaining states are the negative. The dataset is split into training and testing features and labels.

```{r}
mhealth <- Dataset_MHEALTH()

train.label <- mhealth$train.y
train.sample <- mhealth$train.x
test.label <- mhealth$test.y
test.sample <- mhealth$test.x
```

Each row in the data represents a sequence of length 30. 

```{r, }
dim(train.sample)
```

Class 1 represents the positive data and class 0 represents the negative. The imbalance ratio of the train dataset is 1:42.

```{r, }
table(train.label)
```

After Oversampling, the positive and negative observations are balanced.

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```
```{r}
table(over.label)
```

We use the same LSTM classifier, except that we now increase the number of epoches to 200. While, by itself, increasing the number of epoches leads to a performance gain, we are concerned more here with the comparative performance without and with oversampling and less with the absolute gain (which is subject to further parameter tuning).  Figures 11 and 12 show the convergence properties without and with oversampling.

```{r, echo=FALSE, message=FALSE}
pred.label <- as.vector(unlist(rfv$MHp1)) 
lstm.before <- rfv$MHh1 
```

```{r, fig.width = 5, fig.height = 3, fig.cap = "The loss and accuracy of the LSTM classifier trained on the MHEALTH dataset without oversampling. Both metrics are evaluated at the end of each epoch."}
plot(lstm.before)
```

```{r, echo=FALSE, message=FALSE}
pred.label.over <- as.vector(unlist(rfv$MHp2)) 
lstm.after <- rfv$MHh2  
```

```{r, fig.width = 5, fig.height = 3, fig.cap = "The loss and accuracy of the LSTM classifier trained on the MHEALTH dataset with oversampling. Both metrics are evaluated at the end of each epoch."}
plot(lstm.after)
```

Figures 13, 14 and 15 respectively compare the confusion matrices and ROC curves of LSTM without and with oversampling. Before oversampling, the LSTM classifier performance is only marginally better than white noise. However, for the same number of epoches, oversampling improves the performance. Moreover the comparative gain from using OSTSC has increased with a larger training dataset and more epoches. 

```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the MHEALTH dataset without oversampling."}
cm.before <- table(test.label, pred.label)
cm.after <- table(test.label, pred.label.over)

layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 240, 370, col='#3F97D0')
rect(250, 430, 340, 370, col='#F7AD50')
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(195, 435, '0', cex=1.1)
text(295, 435, '1', cex=1.1)
text(125, 370, 'True', cex=1.2, srt=90, font=2)
text(245, 450, 'Predicted', cex=1.2, font=2)
text(140, 400, '0', cex=1.1, srt=90)
text(140, 335, '1', cex=1.1, srt=90)

res <- as.numeric(cm.before)
sum1 <- res[1] + res[3]
sum2 <- res[2] + res[4] 
text(195, 400, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(195, 335, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(295, 400, round(res[3]/sum1, 4), cex=1.3, font=2, col='white')
text(295, 335, round(res[4]/sum2, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the MHEALTH dataset with oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(150, 430, 240, 370, col='#3F97D0')
rect(250, 430, 340, 370, col='#F7AD50')
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(195, 435, '0', cex=1.1)
text(295, 435, '1', cex=1.1)
text(125, 370, 'True', cex=1.2, srt=90, font=2)
text(245, 450, 'Predicted', cex=1.2, font=2)
text(140, 400, '0', cex=1.1, srt=90)
text(140, 335, '1', cex=1.1, srt=90)

res <- as.numeric(cm.after)
sum1 <- res[1] + res[3]
sum2 <- res[2] + res[4] 
text(195, 400, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(195, 335, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(295, 400, round(res[3]/sum1, 4), cex=1.3, font=2, col='white')
text(295, 335, round(res[4]/sum2, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 4, fig.height = 4, fig.cap = "ROC curves of LSTM applied to the MHEALTH dataset, with and without oversampling."}
library(pROC)
par(pty = "s")
plot.roc(as.vector(test.label), pred.label, legacy.axes = TRUE, col = "blue", 
         print.auc = TRUE, print.auc.cex= .8, xlab = 'False Positive Rate', 
         ylab = 'True Positive Rate')
plot.roc(as.vector(test.label), pred.label.over, legacy.axes = TRUE, col = "red", 
         print.auc = TRUE, print.auc.y = .4, print.auc.cex= .8, add = TRUE)
legend("bottomright", legend=c("Without Oversampling", "With Oversampling"), 
       col=c("blue", "red"), lwd=2, cex= .6)
```

#### The high frequency trading dataset

The dataset `Dataset_HFT` has already been introduced in the `Data loading & oversampling` section. The purpose of this example is to demonstrate the application of oversampling to a large sized dataset consisting of 30,000 observations instead of 300. For control, the imbalance ratio of the dataset is configured to be the same as the smaller dataset. We split the training and testing data by a ratio of 1:1. The first half of the time ordered observations are used as training data.

```{r}
HFT <- Dataset_HFT()

label <- HFT$y
sample <- HFT$x
train.label <- label[1:15000]
train.sample <- sample[1:15000, ]
test.label <- label[15001:30000]
test.sample <- sample[15001:30000, ]
```

The imbalance ratio of the training data is 1:48:1.

```{r, }
table(train.label)
```

After oversampling the data is balanced. 

```{r, results='hide'}
MyData <- OSTSC(train.sample, train.label, parallel = FALSE)
over.sample <- MyData$sample
over.label <- MyData$label
```
```{r}
table(over.label)
```

Figures 16 and 17 display the loss and accuracy of LSTM without and with oversampling.

```{r, echo=FALSE, message=FALSE}
pred.label <- as.vector(unlist(rfv$HFTp1)) 
lstm.before <- rfv$HFTh1
```

```{r, fig.width = 5, fig.height = 3, fig.cap = "The loss and accuracy of the LSTM classifier trained on the HFT dataset without oversampling. Both metrics are evaluated at the end of each epoch."}
plot(lstm.before)
```

```{r, echo=FALSE, message=FALSE}
pred.label.over <- as.vector(unlist(rfv$HFTp2)) 
lstm.after <- rfv$HFTh2 
```

```{r, fig.width = 5, fig.height = 3, fig.cap = "The loss and accuracy of the LSTM classifier trained on the oversampled HFT dataset. Both metrics are evaluated at the end of each epoch."}
plot(lstm.after)
```

Figures 18, 19 and 20 respectively compare the confusion matrices and the ROC curves without and with oversampling. The comparative results are similar to the largest MHEALTH dataset - oversampling improves the performance and the comparative gain from using OSTSC only increases with more training observations and more epoches.


```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrices of LSTM applied to the HFT dataset without oversampling."}
cm.before <- table(test.label, pred.label)
cm.after <- table(test.label, pred.label.over)

layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(140, 430, 200, 390, col='#3F97D0')
rect(210, 430, 270, 390, col='#F7AD50')
rect(280, 430, 340, 390, col='#F7AD50')
rect(140, 345, 200, 385, col='#F7AD50')
rect(210, 345, 270, 385, col='#3F97D0')
rect(280, 345, 340, 385, col='#F7AD50')
rect(140, 300, 200, 340, col='#F7AD50')
rect(210, 300, 270, 340, col='#F7AD50')
rect(280, 300, 340, 340, col='#3F97D0')
text(170, 435, '-1', cex=1.1)
text(240, 435, '0', cex=1.1)
text(310, 435, '1', cex=1.1)
text(130, 410, '-1', cex=1.1, srt=90)
text(130, 365, '0', cex=1.1, srt=90)
text(130, 320, '1', cex=1.1, srt=90)
text(120, 370, 'True', cex=1.2, srt=90, font=2)
text(240, 450, 'Predicted', cex=1.2, font=2)
  
res <- as.numeric(cm.before)
sum1 <- res[1] + res[4] + res[7]
sum2 <- res[2] + res[5] + res[8]
sum3 <- res[3] + res[6] + res[9]
text(170, 410, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(170, 365, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(170, 320, round(res[3]/sum3, 4), cex=1.3, font=2, col='white')
text(240, 410, round(res[4]/sum1, 4), cex=1.3, font=2, col='white')
text(240, 365, round(res[5]/sum2, 4), cex=1.3, font=2, col='white')
text(240, 320, round(res[6]/sum3, 4), cex=1.3, font=2, col='white')
text(310, 410, round(res[7]/sum1, 4), cex=1.3, font=2, col='white')
text(310, 365, round(res[8]/sum2, 4), cex=1.3, font=2, col='white')
text(310, 320, round(res[9]/sum3, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, fig.width = 4, fig.height = 2, fig.cap = "Normalized confusion matrix of LSTM applied to the HFT dataset with oversampling."}
layout(matrix(c(1,1,1)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')

rect(140, 430, 200, 390, col='#3F97D0')
rect(210, 430, 270, 390, col='#F7AD50')
rect(280, 430, 340, 390, col='#F7AD50')
rect(140, 345, 200, 385, col='#F7AD50')
rect(210, 345, 270, 385, col='#3F97D0')
rect(280, 345, 340, 385, col='#F7AD50')
rect(140, 300, 200, 340, col='#F7AD50')
rect(210, 300, 270, 340, col='#F7AD50')
rect(280, 300, 340, 340, col='#3F97D0')
text(170, 435, '-1', cex=1.1)
text(240, 435, '0', cex=1.1)
text(310, 435, '1', cex=1.1)
text(130, 410, '-1', cex=1.1, srt=90)
text(130, 365, '0', cex=1.1, srt=90)
text(130, 320, '1', cex=1.1, srt=90)
text(120, 370, 'True', cex=1.2, srt=90, font=2)
text(240, 450, 'Predicted', cex=1.2, font=2)

res <- as.numeric(cm.after)
sum1 <- res[1] + res[4] + res[7]
sum2 <- res[2] + res[5] + res[8]
sum3 <- res[3] + res[6] + res[9]
text(170, 410, round(res[1]/sum1, 4), cex=1.3, font=2, col='white')
text(170, 365, round(res[2]/sum2, 4), cex=1.3, font=2, col='white')
text(170, 320, round(res[3]/sum3, 4), cex=1.3, font=2, col='white')
text(240, 410, round(res[4]/sum1, 4), cex=1.3, font=2, col='white')
text(240, 365, round(res[5]/sum2, 4), cex=1.3, font=2, col='white')
text(240, 320, round(res[6]/sum3, 4), cex=1.3, font=2, col='white')
text(310, 410, round(res[7]/sum1, 4), cex=1.3, font=2, col='white')
text(310, 365, round(res[8]/sum2, 4), cex=1.3, font=2, col='white')
text(310, 320, round(res[9]/sum3, 4), cex=1.3, font=2, col='white')
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 4, fig.height = 4, fig.cap = "ROC curves of LSTM applied to the HFT dataset with and without oversampling."}
library(pROC)
par(pty = "s")
plot.roc(as.vector(test.label), pred.label, legacy.axes = TRUE, col = "blue", print.auc = TRUE,  
         print.auc.cex= .8, xlab = 'False Positive Rate', ylab = 'True Positive Rate')
plot.roc(as.vector(test.label), pred.label.over, legacy.axes = TRUE, col = "red", print.auc = TRUE,   
         print.auc.y = .4, print.auc.cex= .8, add = TRUE)
legend("bottomright", legend=c("Before Oversampling", "After Oversampling"), 
       col=c("blue", "red"), lwd=2, cex= .6)
```


## Summary
The `OSTSC` package is a powerful oversampling approach for classifying univariant, but multinomial time series data. This vignette provides a brief overview of the over-sampling methodology implemented by the package. We first provide three examples for the user to verify correct package installation and reproduceability of the results. Using a 'TensorFlow' implementation of a LSTM architecture, we compared the classifier with and without oversampling. Maintaining the imbalance ratio, we then repeated the evaluation on two medium size datasets. Finally, two large datasets are evaluated to demonstrate the scalability of the package. The examples serve to demonstrate that the OSTSC package improves the performance of RNN classifiers applied to highly imbalanced time series data.

## References

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
#read.bibtex(file = "referenceOSTSC.bib")
```
